{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from math import log10, floor\n",
    "import os\n",
    "\n",
    "from relational_rnn_models import RelationalMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "n_vars = 3\n",
    "var_ids = list(range(n_vars))\n",
    "var_names = ['var' + str(i) for i in var_ids]\n",
    "var_weights = [0.1, 0.6, 0.3] # variable distribution of mock data\n",
    "n_time_steps = 6\n",
    "n_individuals = 1000\n",
    "\n",
    "noise_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function(s)\n",
    "\n",
    "# round a number to n significant digits\n",
    "def round_to_n(x, n = 2):\n",
    "    return round(x, -int(floor(log10(abs(x)))) + (n - 1)) if x != 0 else 0\n",
    "\n",
    "# visualize the output of the generator\n",
    "def visualize_output(generator, z, n = 2):\n",
    "    p = generator(z).view(n_time_steps, n_vars)\n",
    "    p.shape\n",
    "    for t in range(p.shape[0]):\n",
    "        tmp = []\n",
    "        for f in range(p.shape[1]):\n",
    "            tmp.append(round_to_n(p[t,f], n))\n",
    "        print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mock data\n",
    "\n",
    "events = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for indv in range(n_individuals):\n",
    "    tmp = []\n",
    "    for t in range(n_time_steps):\n",
    "        if t > 0 and tmp[t - 1] == 'var2':\n",
    "            weights = [0.7, 0.2, 0.1]\n",
    "            var = np.random.choice(var_names, p=weights)\n",
    "        else:\n",
    "            var = np.random.choice(var_names, p=var_weights)\n",
    "        tmp.append(var)\n",
    "    events.append(tmp)\n",
    "        \n",
    "print('time taken:', round_to_n(time.time() - start_time), 'seconds')\n",
    "\n",
    "for i in range(10):\n",
    "    print(events[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var0': 0, 'var1': 1, 'var2': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 2, 0],\n",
       "        [0, 1, 2, 0, 1, 1],\n",
       "        [1, 1, 2, 0, 2, 0],\n",
       "        [1, 1, 1, 1, 1, 2],\n",
       "        [2, 0, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [2, 1, 2, 0, 2, 0],\n",
       "        [2, 0, 2, 0, 0, 0],\n",
       "        [1, 1, 1, 2, 0, 1],\n",
       "        [1, 1, 1, 2, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_to_indices = dict([(v, i) for i, v in enumerate(var_names)])\n",
    "print(vars_to_indices)\n",
    "data = torch.tensor([[vars_to_indices[e] for e in event] for event in events])\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator\n",
    "\n",
    "'''\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, mem_slots, head_size, num_heads, temperature, vocab_size, embed_vector_size, sequence_length):\n",
    "        super(Generator, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_vector_size)\n",
    "        self.relational_memory = RelationalMemory(mem_slots, head_size, embed_vector_size, num_heads)\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        \n",
    "        self.output_layer = nn.Linear(self.relational_memory.mem_size * self.relational_memory.mem_slots, vocab_size)\n",
    "    \n",
    "    # This function introduces the randomness into the generator; no need for additional random noise input?\n",
    "    def gumbel_softmax(self, output, temperature, eps = 1e-10):\n",
    "        u = torch.rand(output.shape)\n",
    "        g = -torch.log(-torch.log(u + eps) + eps)\n",
    "        result = torch.mul(output.add(g), temperature)\n",
    "        result = F.softmax(result, dim=1)\n",
    "        next_token = torch.argmax(result, dim=1)\n",
    "        return result, next_token\n",
    "    \n",
    "    def forward_step(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, start_token):\n",
    "        memory = self.relational_memory.initial_state(batch_size = 1)\n",
    "        token = start_token\n",
    "        for i in range(self.sequence_length):\n",
    "            embed = self.embed(token)\n",
    "            output, memory = self.relational_memory(embed, memory)\n",
    "            output = self.output_layer(output)\n",
    "            output, token = self.gumbel_softmax(output, self.temperature)\n",
    "        return output, memory\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7778,  0.8254],\n",
      "         [-0.9909,  0.1857],\n",
      "         [-1.0551, -1.6426],\n",
      "         [ 0.1763,  1.5427],\n",
      "         [-0.1829, -0.3588],\n",
      "         [-0.7206,  0.4743]]])\n",
      "tensor([[[1., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.]]])\n",
      "tensor([[0.5593, 0.0915, 0.3492]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[[-0.4666, -1.3479, -0.5847,  2.1674,  0.8708,  0.4461],\n",
      "         [-0.5139,  2.5175, -0.0375,  1.5114,  0.0572,  0.2540],\n",
      "         [-0.7707, -1.4941,  0.3154,  2.0375,  0.1664,  0.2389],\n",
      "         [-0.8530, -1.9771, -0.8000,  2.7497,  0.9198,  0.4457]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "G = RelationalMemory(mem_slots = 4, head_size = 2, num_heads = 3, num_tokens = n_vars, temperature = 1, embed_vector_size = 2, sequence_length = n_time_steps)\n",
    "#print(G.state_dict())\n",
    "inp = data[0, :].view(1, -1)\n",
    "#inp = torch.randn(1, n_time_steps, noise_length)\n",
    "print(inp)\n",
    "logits, memory = G(inp)\n",
    "print(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([[[-1.4959,  1.1291, -0.6207, -0.3380]]], grad_fn=<EmbeddingBackward>)\n",
      "torch.Size([1, 1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[2]])\n",
    "print(test.shape)\n",
    "embed = nn.Embedding(10, 4)\n",
    "test_embed = embed(test)\n",
    "print(test_embed)\n",
    "print(test_embed.shape)\n",
    "test_inp = test_embed[:, 0]\n",
    "print(test_inp.shape)\n",
    "test_inp = test_inp.view(test_inp.shape[0], -1)\n",
    "print(test_inp.shape)\n",
    "test_inp.unsqueeze(dim=1).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
