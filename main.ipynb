{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from math import log10, floor\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from math import ceil, isnan\n",
    "import sys\n",
    "try:\n",
    "    import torchtext\n",
    "    from torchtext.data import Field, Iterator, Dataset, Example\n",
    "except ImportError: \n",
    "    !{'/opt/anaconda3/bin/python3'} -m pip install --upgrade git+https://github.com/pytorch/text\n",
    "    import torchtext\n",
    "    from torchtext.data import Field, Iterator, Dataset\n",
    "\n",
    "from relational_rnn_models import RelationalMemoryGenerator\n",
    "from discriminator import RelGANDiscriminator\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# Try setting the device to a GPU\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function(s)\n",
    "\n",
    "# round a number to n significant digits\n",
    "def round_to_n(x, n = 2):\n",
    "    return round(x, -int(floor(log10(abs(x)))) + (n - 1)) if x != 0 else 0\n",
    "\n",
    "# Transform a date string into a datetime object\n",
    "def str_to_datetime(string):\n",
    "    return datetime.datetime.strptime(string, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# TODO: more complex reduction: takes into account different ICD groups?\n",
    "def reduce_icd(icd_full):\n",
    "    return icd_full[:2]\n",
    "\n",
    "def get_distribution(data, vocab_size):\n",
    "    counts = torch.zeros(vocab_size)\n",
    "\n",
    "    for i in range(vocab_size):\n",
    "        counts[i] = torch.sum(data == i)\n",
    "\n",
    "    freqs = counts / torch.sum(counts)\n",
    "    \n",
    "    return counts, freqs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_codes = pd.read_csv('D_ICD_DIAGNOSES.csv.gz', compression='gzip', index_col='ROW_ID')\n",
    "\n",
    "date_time_events = pd.read_csv('DATETIMEEVENTS.csv.gz', compression='gzip', usecols=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME'])\n",
    "\n",
    "diagnoses = pd.read_csv('DIAGNOSES_ICD.csv.gz', compression='gzip', usecols=['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD9_CODE'])\n",
    "\n",
    "date_time_events['CHARTTIME'] = date_time_events['CHARTTIME'].map(str_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SUBJECT_ID  HADM_ID ICD9_CODE\n",
      "0          109   172335        40\n",
      "14         109   173633        40\n",
      "28         112   174105        53\n",
      "33         113   109976        19\n",
      "36         114   178393        41\n",
      "   SUBJECT_ID   HADM_ID           CHARTTIME\n",
      "0       58526  100001.0 2117-09-11 11:47:00\n",
      "1       54610  100003.0 2150-04-17 15:35:00\n",
      "2       23018  100007.0 2145-03-31 10:15:00\n",
      "3         533  100009.0 2162-05-17 10:18:00\n",
      "4       55853  100010.0 2109-12-10 21:58:00\n"
     ]
    }
   ],
   "source": [
    "filtered_diagnoses = diagnoses[diagnoses['SEQ_NUM'] == 1.0].drop('SEQ_NUM', axis=1)\n",
    "\n",
    "filtered_diagnoses['ICD9_CODE'] = filtered_diagnoses['ICD9_CODE'].map(reduce_icd)\n",
    "\n",
    "print(filtered_diagnoses.head())\n",
    "\n",
    "def apply_func(x):\n",
    "    return x.loc[x['CHARTTIME'].idxmin()]\n",
    "\n",
    "processed_events = date_time_events.groupby('HADM_ID').apply(apply_func).reset_index(drop=True)\n",
    "print(processed_events.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>40</td>\n",
       "      <td>2141-09-20 20:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>173633</td>\n",
       "      <td>40</td>\n",
       "      <td>2141-12-08 01:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>124</td>\n",
       "      <td>112906</td>\n",
       "      <td>44</td>\n",
       "      <td>2161-12-24 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124</td>\n",
       "      <td>134369</td>\n",
       "      <td>44</td>\n",
       "      <td>2165-05-30 08:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124</td>\n",
       "      <td>138376</td>\n",
       "      <td>56</td>\n",
       "      <td>2166-01-09 13:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID ICD9_CODE           CHARTTIME\n",
       "0         109   172335        40 2141-09-20 20:44:00\n",
       "1         109   173633        40 2141-12-08 01:41:00\n",
       "5         124   112906        44 2161-12-24 12:00:00\n",
       "6         124   134369        44 2165-05-30 08:59:00\n",
       "7         124   138376        56 2166-01-09 13:05:00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(filtered_diagnoses, processed_events)\n",
    "#merged.isnull().any() # All False\n",
    "\n",
    "def filter_func(x):\n",
    "    return len(x) > 1\n",
    "\n",
    "final_events = merged.groupby('SUBJECT_ID').filter(filter_func)#.reset_index(drop=True)\n",
    "final_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4337.000000\n",
      "mean      468.675121\n",
      "std       570.848641\n",
      "min         0.000000\n",
      "25%        52.000000\n",
      "50%       217.000000\n",
      "75%       689.000000\n",
      "max      2991.000000\n",
      "dtype: float64\n",
      "count    4337.000000\n",
      "mean        2.620936\n",
      "std         1.476196\n",
      "min         2.000000\n",
      "25%         2.000000\n",
      "50%         2.000000\n",
      "75%         3.000000\n",
      "max        33.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(final_events.groupby('SUBJECT_ID').apply(lambda x: (x['CHARTTIME'].max() - x['CHARTTIME'].min()).days).describe())\n",
    "print(final_events.groupby('SUBJECT_ID').apply(lambda x: len(x)).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = final_events.groupby('SUBJECT_ID').apply(lambda x: len(x)).max()\n",
    "\n",
    "def get_sequence_of_codes(subject):\n",
    "    #codes = ['None' for _ in range(sequence_length)]\n",
    "    codes = []\n",
    "    \n",
    "    for enum, i in enumerate(subject.sort_values('CHARTTIME').index):\n",
    "        #codes[enum] = subject.loc[i, 'ICD9_CODE']\n",
    "        codes.append(subject.loc[i, 'ICD9_CODE'])\n",
    "        \n",
    "    #res = pd.Series(codes)\n",
    "    res = ' '.join(codes)\n",
    "    return res\n",
    "\n",
    "def get_sequence_of_time_differences(subject):\n",
    "    #times = [0 for _ in range(sequence_length)]\n",
    "    times = []\n",
    "    \n",
    "    day0 = subject['CHARTTIME'].min()\n",
    "    \n",
    "    for enum, i in enumerate(subject.sort_values('CHARTTIME').index):\n",
    "        #times[enum] = (subject.loc[i, 'CHARTTIME'] - day0).days\n",
    "        times.append((subject.loc[i, 'CHARTTIME'] - day0).days)\n",
    "        \n",
    "    #res = pd.Series(times)\n",
    "    res = times\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT_ID\n",
      "17       74 42\n",
      "21       41 03\n",
      "23       41 22\n",
      "36    41 99 55\n",
      "68       04 04\n",
      "dtype: object\n",
      "(4337,)\n",
      "SUBJECT_ID\n",
      "17         [0, 131]\n",
      "21         [0, 140]\n",
      "23        [0, 1507]\n",
      "36    [0, 12, 1103]\n",
      "68          [0, 22]\n",
      "dtype: object\n",
      "(4337,)\n"
     ]
    }
   ],
   "source": [
    "sequences_of_codes = final_events.groupby('SUBJECT_ID').apply(get_sequence_of_codes)\n",
    "print(sequences_of_codes.head())\n",
    "print(sequences_of_codes.shape)\n",
    "\n",
    "sequences_of_times = final_events.groupby('SUBJECT_ID').apply(get_sequence_of_time_differences)\n",
    "print(sequences_of_times.head())\n",
    "print(sequences_of_times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4337, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>TIME_FROM_PREVIOUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74 42</td>\n",
       "      <td>[0, 131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41 03</td>\n",
       "      <td>[0, 140]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>41 22</td>\n",
       "      <td>[0, 1507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>41 99 55</td>\n",
       "      <td>[0, 12, 1103]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>04 04</td>\n",
       "      <td>[0, 22]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ICD9_CODE TIME_FROM_PREVIOUS\n",
       "SUBJECT_ID                             \n",
       "17             74 42           [0, 131]\n",
       "21             41 03           [0, 140]\n",
       "23             41 22          [0, 1507]\n",
       "36          41 99 55      [0, 12, 1103]\n",
       "68             04 04            [0, 22]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sequences = pd.DataFrame({'ICD9_CODE': sequences_of_codes.stack(), 'TIME_FROM_PREVIOUS': sequences_of_times.stack()})\n",
    "sequences = pd.DataFrame({'ICD9_CODE': sequences_of_codes, 'TIME_FROM_PREVIOUS': sequences_of_times})\n",
    "print(sequences.shape)\n",
    "sequences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52602071/dataframe-as-datasource-in-torchtext\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "            examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): use only exanples for which\n",
    "                filter_pred(example) is true, or use all examples if None.\n",
    "                Default is None\n",
    "        \"\"\"\n",
    "        self.fields = dict(fields)\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(self.fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "\n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "        for key, field in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split(' ')\n",
    "\n",
    "ICD9_CODE = Field(fix_length = sequence_length, tokenize = tokenize)\n",
    "\n",
    "fields = [('ICD9_CODE', ICD9_CODE), ('TIME_FROM_PREVIOUS', None)]\n",
    "\n",
    "dataset = DataFrameDataset(sequences, fields)\n",
    "\n",
    "ICD9_CODE.build_vocab(dataset)\n",
    "#dataset.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "00\n",
      "96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'74': 14,\n",
       "         '42': 1185,\n",
       "         '41': 733,\n",
       "         '03': 1186,\n",
       "         '22': 28,\n",
       "         '99': 980,\n",
       "         '55': 139,\n",
       "         '04': 60,\n",
       "         '27': 129,\n",
       "         '33': 21,\n",
       "         '53': 261,\n",
       "         '71': 51,\n",
       "         '43': 456,\n",
       "         '40': 150,\n",
       "         '45': 155,\n",
       "         '96': 84,\n",
       "         '48': 407,\n",
       "         '44': 269,\n",
       "         '56': 294,\n",
       "         '18': 30,\n",
       "         '85': 153,\n",
       "         '57': 680,\n",
       "         '32': 35,\n",
       "         '16': 91,\n",
       "         '49': 197,\n",
       "         '15': 139,\n",
       "         '19': 230,\n",
       "         '34': 135,\n",
       "         '50': 204,\n",
       "         '58': 211,\n",
       "         'V3': 32,\n",
       "         '77': 15,\n",
       "         '39': 75,\n",
       "         '51': 783,\n",
       "         '23': 19,\n",
       "         '07': 50,\n",
       "         '25': 333,\n",
       "         '11': 26,\n",
       "         '69': 14,\n",
       "         '80': 131,\n",
       "         'V5': 55,\n",
       "         '78': 104,\n",
       "         '59': 92,\n",
       "         '20': 91,\n",
       "         '82': 65,\n",
       "         '00': 86,\n",
       "         '52': 6,\n",
       "         '79': 34,\n",
       "         '72': 51,\n",
       "         '93': 14,\n",
       "         '28': 76,\n",
       "         '73': 67,\n",
       "         '68': 32,\n",
       "         '29': 139,\n",
       "         '75': 8,\n",
       "         '76': 12,\n",
       "         '05': 5,\n",
       "         '86': 30,\n",
       "         '21': 20,\n",
       "         '81': 13,\n",
       "         '30': 14,\n",
       "         '46': 14,\n",
       "         '14': 7,\n",
       "         '97': 12,\n",
       "         '24': 3,\n",
       "         '47': 17,\n",
       "         '01': 4,\n",
       "         '02': 3,\n",
       "         '67': 1,\n",
       "         '35': 16,\n",
       "         '92': 4,\n",
       "         '95': 9,\n",
       "         '63': 1,\n",
       "         '61': 3,\n",
       "         '13': 8,\n",
       "         '87': 2,\n",
       "         '17': 9,\n",
       "         '54': 13,\n",
       "         '60': 4,\n",
       "         '70': 4,\n",
       "         '84': 1,\n",
       "         '26': 2,\n",
       "         '98': 6,\n",
       "         '90': 4,\n",
       "         '94': 1,\n",
       "         '09': 5,\n",
       "         '88': 1,\n",
       "         '36': 1,\n",
       "         'V7': 1,\n",
       "         '83': 1,\n",
       "         '08': 2,\n",
       "         'V0': 1,\n",
       "         '12': 4,\n",
       "         '37': 1,\n",
       "         '62': 1,\n",
       "         '64': 2})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ICD9_CODE.vocab.stoi['00'])\n",
    "print(ICD9_CODE.vocab.itos[31])\n",
    "vocab_size = len(ICD9_CODE.vocab.freqs)\n",
    "print(vocab_size)\n",
    "ICD9_CODE.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  3,  1,  ...,  1,  1,  1],\n",
       "        [ 7,  7, 18,  ...,  1,  1,  1],\n",
       "        [ 2, 26, 31,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 3,  7,  1,  ...,  1,  1,  1],\n",
       "        [ 2,  2, 32,  ...,  1,  1,  1],\n",
       "        [ 9,  5,  1,  ...,  1,  1,  1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "data_iter = Iterator(dataset, batch_size = batch_size)#, device = device)\n",
    "\n",
    "next(iter(data_iter)).ICD9_CODE.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4337\n"
     ]
    }
   ],
   "source": [
    "subjects = pd.unique(final_events['SUBJECT_ID'])\n",
    "n_individuals = len(subjects)\n",
    "print(n_individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(sequence_length, sequence_length * len(subjects))\\n\\nflat_codes = sequences_of_codes.values.flatten()\\nflat_codes = flat_codes[flat_codes != 'None']\\n\\ncodes = np.concatenate([np.array(['None']), np.unique(flat_codes)])\\nprint(codes)\\n\\ncodes_size = len(codes)\\nprint(codes_size)\\n\\ncode_to_index = dict([(c, i) for i, c in enumerate(codes)])\\nindex_to_code = dict([(i, c) for i, c in enumerate(codes)])\\n\\nprint(index_to_code[12], type(index_to_code[12]))\\nprint(code_to_index['77'])\\nprint(code_to_index['None'] == 0)\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#divisor = 365 * 5\n",
    "#sequence_length = ceil((t1 - t0).days / divisor)\n",
    "'''\n",
    "print(sequence_length, sequence_length * len(subjects))\n",
    "\n",
    "flat_codes = sequences_of_codes.values.flatten()\n",
    "flat_codes = flat_codes[flat_codes != 'None']\n",
    "\n",
    "codes = np.concatenate([np.array(['None']), np.unique(flat_codes)])\n",
    "print(codes)\n",
    "\n",
    "codes_size = len(codes)\n",
    "print(codes_size)\n",
    "\n",
    "code_to_index = dict([(c, i) for i, c in enumerate(codes)])\n",
    "index_to_code = dict([(i, c) for i, c in enumerate(codes)])\n",
    "\n",
    "print(index_to_code[12], type(index_to_code[12]))\n",
    "print(code_to_index['77'])\n",
    "print(code_to_index['None'] == 0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_seqs = torch.zeros(n_individuals, 2, sequence_length)\\n\\ndata_seqs[:, 0, :] = torch.from_numpy(sequences_of_codes.apply(lambda x: x.apply(lambda y: code_to_index[y])).values)\\ndata_seqs[:, 1, :] = torch.from_numpy(sequences_of_times.values)\\n\\ndata = data_seqs[:, 0, :]\\n\\nprint(data_seqs)\\nprint(data)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the data into a reasonnable format\n",
    "'''\n",
    "data_seqs = torch.zeros(n_individuals, 2, sequence_length)\n",
    "\n",
    "data_seqs[:, 0, :] = torch.from_numpy(sequences_of_codes.apply(lambda x: x.apply(lambda y: code_to_index[y])).values)\n",
    "data_seqs[:, 1, :] = torch.from_numpy(sequences_of_times.values)\n",
    "\n",
    "data = data_seqs[:, 0, :]\n",
    "\n",
    "print(data_seqs)\n",
    "print(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(torch.sum(data != 0).type(torch.FloatTensor) / data.numel()) # Percentage of non-zero elements\\nprint(data[:3])\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(torch.sum(data != 0).type(torch.FloatTensor) / data.numel()) # Percentage of non-zero elements\n",
    "print(data[:3])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncounts, freqs = get_distribution(data, codes_size)\\n\\nprint(counts)\\nprint(freqs)'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the distribution of the data\n",
    "'''\n",
    "counts, freqs = get_distribution(data, codes_size)\n",
    "\n",
    "print(counts)\n",
    "print(freqs)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], device='cuda:0')\n",
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 0, 65,  5, 36,  8, 69,  5, 39, 45, 18, 27, 71, 80, 30, 88, 46,  1, 83,\n",
      "         39, 83, 90, 27, 42, 42, 29, 64, 72, 41, 79, 81, 95, 81, 74]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-1.9889,  0.2935, -0.8093,  1.0253],\n",
      "         [-2.2006,  0.3083, -0.8785,  1.0235],\n",
      "         [-2.1808,  0.2980, -0.8788,  1.0242],\n",
      "         [-2.1454,  0.2995, -0.8676,  1.0240]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test generator output\n",
    "\n",
    "mem_slots = 4\n",
    "head_size = 2\n",
    "embed_size = 2\n",
    "temperature = 1\n",
    "num_heads = 2\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads)\n",
    "\n",
    "start_token = torch.tensor([[0]])\n",
    "memory = G.initial_state(batch_size = 1)\n",
    "\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    start_token = start_token.cuda()\n",
    "    memory = memory.cuda()\n",
    "\n",
    "print(memory)\n",
    "logits, tokens, _, memory = G(start_token, memory, sequence_length, None)\n",
    "print(logits)\n",
    "print(tokens)\n",
    "print(memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3806)\n"
     ]
    }
   ],
   "source": [
    "# Define generator evaluation functions\n",
    "\n",
    "def chi_sqrd_dist(counts1, counts2):\n",
    "    counts1 = counts1.view(1, -1)\n",
    "    counts2 = counts2.view(1, -1)\n",
    "    table = torch.cat([counts1, counts2], dim = 0)\n",
    "    col_sums = torch.sum(table, dim = 0)\n",
    "    row_sums = torch.sum(table, dim = 1)\n",
    "    n = torch.sum(col_sums)\n",
    "    \n",
    "    table_freq = table / n\n",
    "    col_freqs = col_sums / n\n",
    "    row_freqs = row_sums / n\n",
    "    \n",
    "    diffs = table_freq[0, :] / row_freqs[0] - table_freq[1, :] / row_freqs[1]\n",
    "    diffs_sqrd = diffs ** 2\n",
    "    diffs_sqrd_norm = diffs_sqrd / col_freqs\n",
    "    \n",
    "    chi_sqrd_distance = torch.sum(diffs_sqrd_norm)\n",
    "    \n",
    "    return chi_sqrd_distance\n",
    "    \n",
    "def test_special_case(G, ICD9_CODE, start_tokens, vocab_size = vocab_size, sequence_length = sequence_length):\n",
    "    counts_real = ICD9_CODE.vocab.freqs\n",
    "    \n",
    "    memory = G.initial_state(batch_size = start_tokens.shape[0])\n",
    "\n",
    "    if cuda:\n",
    "        memory = memory.cuda()\n",
    "        start_tokens = start_tokens.cuda()\n",
    "    \n",
    "    _, data_fake, _, _ = G(start_tokens, memory, sequence_length)\n",
    "    \n",
    "    counts_fake, freqs_fake = get_distribution(data_fake, vocab_size)\n",
    "    \n",
    "    score = chi_sqrd_dist(counts_real, counts_fake)\n",
    "    return score\n",
    "\n",
    "score = test_special_case(G, ICD9_CODE, data[:50, :1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.3010, 0.3265]], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3137], device='cuda:0', grad_fn=<MeanBackward2>)\n"
     ]
    }
   ],
   "source": [
    "# Test Discriminator output\n",
    "\n",
    "n_embeddings = 2\n",
    "embed_size = 2\n",
    "out_channels = 5 \n",
    "filter_sizes = [2, 3] # values can be at most the sequence_length\n",
    "\n",
    "D = RelGANDiscriminator(n_embeddings, vocab_size, embed_size, sequence_length, out_channels, filter_sizes)\n",
    "\n",
    "if cuda:\n",
    "    D.cuda()\n",
    "\n",
    "inp = logits\n",
    "print(inp)\n",
    "print(D(inp, False))\n",
    "print(D(inp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator pre-train function\n",
    "\n",
    "# TODO: use some data or batch loader from torchtext\n",
    "def pretrain_generator(G, dataset, batch_size, vocab_size, n_epochs, lr, print_step = 10):\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    \n",
    "    sequence_length = train_data.shape[1]\n",
    "    n_individuals = train_data.shape[0]\n",
    "    \n",
    "    if cuda:\n",
    "        G.cuda()\n",
    "        loss_function.cuda()\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        for batch_i in range(0, n_individuals, batch_size):\n",
    "            data = train_data[batch_i:batch_i + batch_size]\n",
    "            data_one_hot = F.one_hot(data, vocab_size).type(Tensor)\n",
    "            \n",
    "            start_token = data[:, :1]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            memory = G.initial_state(batch_size = batch_size)\n",
    "\n",
    "            if cuda:\n",
    "                start_token = start_token.cuda()\n",
    "                memory = memory.cuda()\n",
    "\n",
    "            logits, _, _, _ = G(start_token, memory, sequence_length)\n",
    "\n",
    "            loss = loss_function(logits, data_one_hot)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if e % print_step == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [G loss: %f]\"\n",
    "                % (e, n_epochs, loss.item())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4362)\n",
      "[Epoch 0/10] [G loss: 0.546688]\n",
      "[Epoch 2/10] [G loss: 0.540247]\n",
      "[Epoch 4/10] [G loss: 0.505934]\n",
      "[Epoch 6/10] [G loss: 0.441500]\n",
      "[Epoch 8/10] [G loss: 0.275778]\n",
      "tensor(0.3093)\n"
     ]
    }
   ],
   "source": [
    "mem_slots = 4\n",
    "head_size = 2\n",
    "embed_size = 2\n",
    "temperature = 1\n",
    "num_heads = 2\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads)\n",
    "\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "\n",
    "score = test_special_case(G, data, vocab_size, False)\n",
    "print(score)\n",
    "pretrain_generator(G, data, vocab_size, 10, 0.01, 2)\n",
    "score = test_special_case(G, data, vocab_size, False)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "\n",
    "# TODO: use some data or batch loader from torchtext\n",
    "def train(G, D, train_data, vocab_size, n_epochs, lr, temperature, print_step = 10, score_fn = test_special_case):    \n",
    "    scores = []\n",
    "    \n",
    "    score = test_special_case(G, data, vocab_size, False)\n",
    "    print('Score before training:', score)\n",
    "    scores.append(torch.tensor(score))\n",
    "    \n",
    "    print('pretraining generator...')\n",
    "    pretrain_generator(G, train_data, vocab_size, max(n_epochs // 10, 1), lr * 100, max(n_epochs // 10 - 1, 1))\n",
    "    print('pretraining complete')\n",
    "    \n",
    "    score = test_special_case(G, data, vocab_size, False)\n",
    "    print(\"[Score:\", score, \"]\")\n",
    "    scores.append(torch.tensor(score))\n",
    "    \n",
    "    adversarial_loss = torch.nn.BCELoss()\n",
    "    \n",
    "    optimizer_G = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    optimizer_D = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "    \n",
    "    train_data_one_hot = F.one_hot(train_data, vocab_size).type(Tensor)\n",
    "\n",
    "    start_token = train_data[:, :1]\n",
    "    sequence_length = train_data.shape[1]\n",
    "    \n",
    "    if cuda:\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        adversarial_loss.cuda()\n",
    "        start_token = start_token.cuda()\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(train_data.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(train_data.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        memory = G.initial_state(batch_size = train_data.shape[0])\n",
    "        if cuda:\n",
    "            memory = memory.cuda()\n",
    "        temp = temperature ** ((e + 1) / n_epochs)\n",
    "        fake_one_hot, _, _, _ = G(start_token, memory, sequence_length, temp)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(D(fake_one_hot), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(D(train_data_one_hot), valid)\n",
    "        fake_loss = adversarial_loss(D(fake_one_hot.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if e % print_step == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (e, n_epochs, d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            #print(\"[Frequencies:\", score_fn(G, train_data, vocab_size), \"]\")\n",
    "            score = test_special_case(G, data, vocab_size, False)\n",
    "            print(\"[Score:\", score, \"]\")\n",
    "            scores.append(torch.tensor(score))\n",
    "            \n",
    "    score = test_special_case(G, data, vocab_size, False)\n",
    "    print('Score after training:', score)\n",
    "    scores.append(torch.tensor(score))\n",
    "            \n",
    "    #return scores\n",
    "    return torch.stack(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 10.76 GiB already allocated; 11.56 MiB free; 107.37 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-a18a63fcb022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mfreqs_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_special_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distribution before training:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'benchmark distribution:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-5c73cca9dc5a>\u001b[0m in \u001b[0;36mtest_special_case\u001b[0;34m(G, data, vocab_size, return_freq)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcounts_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FinnGAN/relational_rnn_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, start_token, memory, sequence_length, temperature, targets, require_logits)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FinnGAN/relational_rnn_models.py\u001b[0m in \u001b[0;36mforward_step\u001b[0;34m(self, token, memory, temperature, treat_input_as_matrix)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mmemory_plus_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mnext_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattend_over_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_plus_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# cut out the concatenated input vectors from the original memory slots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FinnGAN/relational_rnn_models.py\u001b[0m in \u001b[0;36mattend_over_memory\u001b[0;34m(self, memory)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mattended_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultihead_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;31m# Add a skip connection to the multiheaded attention's input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FinnGAN/relational_rnn_models.py\u001b[0m in \u001b[0;36mmultihead_attention\u001b[0;34m(self, memory)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# First, a simple linear projection is used to construct queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_projector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# apply layernorm for every dim except the batch dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 10.76 GiB already allocated; 11.56 MiB free; 107.37 MiB cached)"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generator params\n",
    "mem_slots = 1\n",
    "head_size = 6\n",
    "embed_size = 10\n",
    "temperature = 100\n",
    "num_heads = 10\n",
    "num_blocks = 6\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads, num_blocks)\n",
    "\n",
    "# Discriminator params\n",
    "n_embeddings = 5\n",
    "embed_size = embed_size\n",
    "out_channels = 15\n",
    "filter_sizes = [2, 3, 4] # values can be at most the sequence_length\n",
    "\n",
    "D = RelGANDiscriminator(n_embeddings, vocab_size, embed_size, sequence_length, out_channels, filter_sizes)\n",
    "\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "\n",
    "freqs_fake = test_special_case(G, data, vocab_size)\n",
    "print('distribution before training:', freqs_fake)\n",
    "print('benchmark distribution:', freqs)\n",
    "\n",
    "# Train the GAN\n",
    "scores = train(G, D, data, vocab_size, 100, 0.0001, temperature, 10)\n",
    "\n",
    "freqs_fake = test_special_case(G, data, vocab_size)\n",
    "print('distributions after training:', freqs_fake)\n",
    "print('benchmark distribution:', freqs)\n",
    "\n",
    "print('time taken:', round_to_n(time.time() - start_time), 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(scores.shape[0]), scores[:, 0].numpy())\n",
    "plt.plot(range(scores.shape[0]), scores[:, 1].numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
