{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from math import log10, floor\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from relational_rnn_models import RelationalMemoryGenerator\n",
    "from discriminator import RelGANDiscriminator\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# Try setting the device to a GPU\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89527\n",
      "['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
      "1143\n",
      "nobility\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "\n",
    "with open('aclImbd/imdb.vocab', 'r') as file:\n",
    "    for line in file:\n",
    "        vocab.append(line[:-1])\n",
    "        \n",
    "        \n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "print(vocab[:10])\n",
    "\n",
    "word_to_index = dict([(w, i) for i, w in enumerate(vocab)])\n",
    "index_to_word = dict([(i, w) for i, w in enumerate(vocab)])\n",
    "\n",
    "print(word_to_index['awesome'])\n",
    "print(index_to_word[12345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('aclImbd/train/pos/*.txt')[:500]\n",
    "print(len(files))\n",
    "\n",
    "lengths = []\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename, 'r') as file:\n",
    "        lengths.append(len(file.readline().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(236.6957)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(torch.tensor(lengths).type(Tensor)))\n",
    "print(min(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0588, 0.3529, 0.1765, 0.2353, 0.1176, 0.0588])\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "vocab_size = 6\n",
    "var_ids = list(range(vocab_size))\n",
    "var_names = ['var' + str(i) for i in var_ids]\n",
    "var_weights = torch.tensor([1, 6, 3, 4, 2, 1]).type(Tensor) \n",
    "var_weights = var_weights / torch.sum(var_weights)# variable distribution of mock data\n",
    "sequence_length = 10\n",
    "n_individuals = 2000\n",
    "\n",
    "#noise_length = 2\n",
    "print(var_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function(s)\n",
    "\n",
    "# round a number to n significant digits\n",
    "def round_to_n(x, n = 2):\n",
    "    return round(x, -int(floor(log10(abs(x)))) + (n - 1)) if x != 0 else 0\n",
    "\n",
    "# visualize the output of the generator\n",
    "def visualize_output(generator, z, n = 2):\n",
    "    p = generator(z).view(sequence_length, vocab_size)\n",
    "    p.shape\n",
    "    for t in range(p.shape[0]):\n",
    "        tmp = []\n",
    "        for f in range(p.shape[1]):\n",
    "            tmp.append(round_to_n(p[t,f], n))\n",
    "        print(tmp)\n",
    "\n",
    "#y = data[:5, :]\n",
    "#print(y)\n",
    "#print(F.one_hot(y, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.56 seconds\n",
      "['var4', 'var1', 'var3', 'var1', 'var0', 'var0', 'var3', 'var3', 'var3', 'var1']\n",
      "['var3', 'var1', 'var1', 'var4', 'var4', 'var4', 'var3', 'var4', 'var5', 'var1']\n",
      "['var2', 'var3', 'var2', 'var0', 'var3', 'var1', 'var3', 'var3', 'var1', 'var1']\n",
      "['var1', 'var1', 'var0', 'var2', 'var1', 'var1', 'var1', 'var5', 'var5', 'var0']\n",
      "['var3', 'var2', 'var1', 'var1', 'var4', 'var0', 'var5', 'var4', 'var3', 'var2']\n",
      "['var2', 'var5', 'var5', 'var3', 'var1', 'var3', 'var0', 'var1', 'var0', 'var1']\n",
      "['var1', 'var3', 'var3', 'var1', 'var1', 'var4', 'var3', 'var5', 'var0', 'var2']\n",
      "['var1', 'var3', 'var3', 'var1', 'var5', 'var3', 'var3', 'var1', 'var1', 'var2']\n",
      "['var1', 'var2', 'var5', 'var1', 'var1', 'var4', 'var2', 'var5', 'var0', 'var2']\n",
      "['var1', 'var3', 'var1', 'var3', 'var2', 'var0', 'var1', 'var3', 'var1', 'var1']\n"
     ]
    }
   ],
   "source": [
    "# Generate mock data\n",
    "\n",
    "events = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "alternative_weights = torch.tensor([7, 2, 1, 2, 1, 4]).type(Tensor) \n",
    "alternative_weights = alternative_weights / torch.sum(alternative_weights)\n",
    "\n",
    "for indv in range(n_individuals):\n",
    "    tmp = []\n",
    "    for t in range(sequence_length):\n",
    "        if t > 0 and tmp[t - 1] == 'var2':\n",
    "            var = np.random.choice(var_names, p=alternative_weights)\n",
    "        else:\n",
    "            var = np.random.choice(var_names, p=var_weights)\n",
    "        tmp.append(var)\n",
    "    events.append(tmp)\n",
    "        \n",
    "print('time taken:', round_to_n(time.time() - start_time), 'seconds')\n",
    "\n",
    "for i in range(10):\n",
    "    print(events[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var0': 0, 'var1': 1, 'var2': 2, 'var3': 3, 'var4': 4, 'var5': 5}\n",
      "tensor([[4, 1, 3, 1, 0, 0, 3, 3, 3, 1],\n",
      "        [3, 1, 1, 4, 4, 4, 3, 4, 5, 1],\n",
      "        [2, 3, 2, 0, 3, 1, 3, 3, 1, 1],\n",
      "        [1, 1, 0, 2, 1, 1, 1, 5, 5, 0],\n",
      "        [3, 2, 1, 1, 4, 0, 5, 4, 3, 2],\n",
      "        [2, 5, 5, 3, 1, 3, 0, 1, 0, 1],\n",
      "        [1, 3, 3, 1, 1, 4, 3, 5, 0, 2],\n",
      "        [1, 3, 3, 1, 5, 3, 3, 1, 1, 2],\n",
      "        [1, 2, 5, 1, 1, 4, 2, 5, 0, 2],\n",
      "        [1, 3, 1, 3, 2, 0, 1, 3, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "vars_to_indices = dict([(v, i) for i, v in enumerate(var_names)])\n",
    "print(vars_to_indices)\n",
    "data = torch.tensor([[vars_to_indices[e] for e in event] for event in events])\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]])\n",
      "tensor([[[1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.]]], grad_fn=<CatBackward>)\n",
      "tensor([[0, 5, 1, 0, 3, 4, 2, 4, 2, 2]])\n",
      "tensor([[[ 0.4614,  1.2949, -0.6494, -2.0191],\n",
      "         [ 0.4594,  1.4459, -0.8590, -2.1287],\n",
      "         [ 0.3686,  1.2222,  0.1015, -1.9834],\n",
      "         [ 0.4619,  1.3342, -0.8642, -1.9224]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test generator output\n",
    "\n",
    "mem_slots = 4\n",
    "head_size = 2\n",
    "embed_size = 2\n",
    "temperature = 1\n",
    "num_heads = 2\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads)\n",
    "\n",
    "start_token = torch.tensor([[0]])\n",
    "memory = G.initial_state(batch_size = 1)\n",
    "print(memory)\n",
    "logits, tokens, _, memory = G(start_token, memory, sequence_length, None)\n",
    "print(logits)\n",
    "print(tokens)\n",
    "print(memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0335, 1.3815, 0.1525, 0.5535, 0.3695, 0.5545])\n",
      "tensor([17.5695,  3.9142,  0.8642,  2.3524,  3.1407,  9.4265])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joonasav/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2201, 0.1639, 0.1563, 0.1476, 0.1505, 0.1617]) tensor([0.2260, 0.1565, 0.1465, 0.1685, 0.1449, 0.1576])\n"
     ]
    }
   ],
   "source": [
    "# Define generator evaluation functions\n",
    "\n",
    "def eval_generator(G, data, vocab_size):\n",
    "    _, data_fake, _, _ = G(data[:, :1], G.initial_state(batch_size = data.shape[0]), data.shape[1])\n",
    "    word_means = torch.stack([torch.mean((data == i).type(torch.FloatTensor), dim = 0) for i in range(vocab_size)])\n",
    "    word_means_fake = torch.stack([torch.mean((data_fake == i).type(torch.FloatTensor), dim = 0) for i in range(vocab_size)])\n",
    "    \n",
    "    scores = torch.sum(torch.abs(word_means - word_means_fake), dim = 1)\n",
    "    \n",
    "    return scores # for each word; the lower the better\n",
    "\n",
    "def count_special_cases(data, vocab_size):\n",
    "    counts1 = torch.zeros(vocab_size)\n",
    "    counts2 = torch.zeros(vocab_size)\n",
    "    for i in range(data.shape[0]):\n",
    "        for t in range(data.shape[1] - 1):\n",
    "            if data[i, t] == 2:\n",
    "                counts1[data[i, t + 1]] += 1\n",
    "            else:\n",
    "                counts2[data[i, t + 1]] += 1\n",
    "                \n",
    "    return counts1, counts2\n",
    "\n",
    "def test_special_case(G, data, vocab_size, return_freq = True):\n",
    "    counts_real1, counts_real2 = count_special_cases(data, vocab_size)\n",
    "    freq_real1 = counts_real1 / torch.sum(counts_real1)\n",
    "    freq_real2 = counts_real2 / torch.sum(counts_real2)\n",
    "    \n",
    "    _, data_fake, _, _ = G(data[:, :1], G.initial_state(batch_size = data.shape[0]), data.shape[1])\n",
    "    \n",
    "    counts_fake1, counts_fake2 = count_special_cases(data_fake, vocab_size)\n",
    "    freq_fake1 = counts_fake1 / torch.sum(counts_fake1)\n",
    "    freq_fake2 = counts_fake2 / torch.sum(counts_fake2)\n",
    "    \n",
    "    scores1 = freq_real1 - freq_fake1\n",
    "    scores2 = freq_real2 - freq_fake2\n",
    "    #print(freq_real1, freq_real2)\n",
    "    \n",
    "    if return_freq:\n",
    "        return freq_fake1, freq_fake2\n",
    "    else:\n",
    "        return torch.mean(torch.abs(scores1)), torch.mean(torch.abs(scores2))\n",
    "\n",
    "#print(data[:5, :])\n",
    "scores = eval_generator(G, data, vocab_size)\n",
    "print(scores)\n",
    "print(scores / torch.tensor(var_weights)) # adjusted to the words' frequencies\n",
    "\n",
    "scores1, scores2 = test_special_case(G, data, vocab_size)\n",
    "print(scores1, scores2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.]]], grad_fn=<CatBackward>)\n",
      "tensor([[0.5249, 0.5356]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.5302], grad_fn=<MeanBackward2>)\n"
     ]
    }
   ],
   "source": [
    "# Test Discriminator output\n",
    "\n",
    "n_embeddings = 2\n",
    "embed_size = 2\n",
    "out_channels = 5 \n",
    "filter_sizes = [2, 3] # values can be at most the sequence_length\n",
    "\n",
    "D = RelGANDiscriminator(n_embeddings, vocab_size, embed_size, sequence_length, out_channels, filter_sizes)\n",
    "\n",
    "inp = logits\n",
    "print(inp)\n",
    "print(D(inp, False))\n",
    "print(D(inp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator pre-train function\n",
    "\n",
    "def pretrain_generator(G, train_data, vocab_size, n_epochs, lr, print_step = 10):\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    \n",
    "    if cuda:\n",
    "        G.cuda()\n",
    "        loss_function.cuda()\n",
    "    \n",
    "    train_data_one_hot = F.one_hot(train_data, vocab_size).type(Tensor)\n",
    "    start_token = train_data[:, :1]\n",
    "    sequence_length = train_data.shape[1]\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        memory = G.initial_state(batch_size = train_data.shape[0])\n",
    "        \n",
    "        logits, _, _, _ = G(start_token, memory, sequence_length)\n",
    "        \n",
    "        loss = loss_function(logits, train_data_one_hot)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if e % print_step == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [G loss: %f]\"\n",
    "                % (e, n_epochs, loss.item())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joonasav/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4190, 1.5945, 0.5430, 0.9085, 0.2780, 0.6490]) tensor([ 7.1230,  4.5178,  3.0770,  3.8611,  2.3630, 11.0330])\n",
      "[Epoch 0/10] [G loss: 6.503215]\n",
      "[Epoch 2/10] [G loss: 6.524394]\n",
      "[Epoch 4/10] [G loss: 6.494467]\n",
      "[Epoch 6/10] [G loss: 6.566292]\n",
      "[Epoch 8/10] [G loss: 6.625226]\n",
      "tensor([0.1080, 0.4580, 0.1670, 0.6595, 0.1635, 0.5290]) tensor([1.8360, 1.2977, 0.9463, 2.8029, 1.3897, 8.9930])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joonasav/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "mem_slots = 4\n",
    "head_size = 2\n",
    "embed_size = 2\n",
    "temperature = 1\n",
    "num_heads = 2\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads)\n",
    "\n",
    "scores = eval_generator(G, data, vocab_size)\n",
    "print(scores, scores / torch.tensor(var_weights))\n",
    "pretrain_generator(G, data, vocab_size, 10, 0.001, 2)\n",
    "scores = eval_generator(G, data, vocab_size)\n",
    "print(scores, scores / torch.tensor(var_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "\n",
    "def train(G, D, train_data, vocab_size, n_epochs, lr, temperature, print_step = 10, score_fn = test_special_case):\n",
    "    print('pretraining generator...')\n",
    "    pretrain_generator(G, train_data, vocab_size, n_epochs // 10, lr, n_epochs // 10 - 1)\n",
    "    print('pretraining complete')\n",
    "    \n",
    "    adversarial_loss = torch.nn.BCELoss()\n",
    "    \n",
    "    if cuda:\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        adversarial_loss.cuda()\n",
    "    \n",
    "    optimizer_G = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    optimizer_D = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "    \n",
    "    train_data_one_hot = F.one_hot(train_data, vocab_size).type(Tensor)\n",
    "\n",
    "    start_token = train_data[:, :1]\n",
    "    sequence_length = train_data.shape[1]\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(train_data.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(train_data.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        memory = G.initial_state(batch_size = train_data.shape[0])\n",
    "        temp = temperature #** ((e + 1) / n_epochs)\n",
    "        fake_one_hot, _, _, _ = G(start_token, memory, sequence_length, temp)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(D(fake_one_hot), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(D(train_data_one_hot), valid)\n",
    "        fake_loss = adversarial_loss(D(fake_one_hot.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if e % print_step == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (e, n_epochs, d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            print(\"[Frequencies:\", score_fn(G, train_data, vocab_size), \"]\")\n",
    "            scores1, scores2 = score_fn(G, train_data, vocab_size, False)\n",
    "            print(\"[Scores:\", scores1, scores2, \"]\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "score before training: tensor(0.0991) tensor(0.0994)\n",
      "pretraining generator...\n",
      "[Epoch 0/100] [G loss: 6.931863]\n",
      "[Epoch 99/100] [G loss: 5.767930]\n",
      "pretraining complete\n",
      "[Epoch 0/1000] [D loss: 0.693834] [G loss: 0.816437]\n",
      "[Frequencies: (tensor([0.0804, 0.6686, 0.0588, 0.1059, 0.0510, 0.0353]), tensor([0.0084, 0.9588, 0.0075, 0.0145, 0.0058, 0.0049])) ]\n",
      "[Scores: tensor(0.1974) tensor(0.2033) ]\n",
      "[Epoch 50/1000] [D loss: 0.693121] [G loss: 0.694957]\n",
      "[Frequencies: (tensor([0.1667, 0.1136, 0.1431, 0.2364, 0.1593, 0.1808]), tensor([0.1717, 0.1073, 0.1293, 0.2289, 0.1865, 0.1764])) ]\n",
      "[Scores: tensor(0.1088) tensor(0.1006) ]\n",
      "[Epoch 100/1000] [D loss: 0.693045] [G loss: 0.705340]\n",
      "[Frequencies: (tensor([0.0996, 0.2806, 0.4507, 0.1119, 0.0205, 0.0367]), tensor([0.0933, 0.2826, 0.4541, 0.1121, 0.0227, 0.0353])) ]\n",
      "[Scores: tensor(0.1879) tensor(0.1012) ]\n",
      "[Epoch 150/1000] [D loss: 0.691387] [G loss: 0.689033]\n",
      "[Frequencies: (tensor([0.0877, 0.3184, 0.1281, 0.1910, 0.1457, 0.1291]), tensor([0.0950, 0.3562, 0.1525, 0.1611, 0.1213, 0.1139])) ]\n",
      "[Scores: tensor(0.1370) tensor(0.0324) ]\n",
      "[Epoch 200/1000] [D loss: 0.695998] [G loss: 0.710113]\n",
      "[Frequencies: (tensor([0.3042, 0.2886, 0.2121, 0.1545, 0.0255, 0.0152]), tensor([0.2431, 0.2916, 0.2661, 0.1494, 0.0329, 0.0169])) ]\n",
      "[Scores: tensor(0.1203) tensor(0.0895) ]\n",
      "[Epoch 250/1000] [D loss: 0.683937] [G loss: 0.722259]\n",
      "[Frequencies: (tensor([0.2104, 0.1578, 0.1154, 0.2886, 0.1194, 0.1084]), tensor([0.1119, 0.2807, 0.1416, 0.2793, 0.1124, 0.0742])) ]\n",
      "[Scores: tensor(0.1155) tensor(0.0398) ]\n",
      "[Epoch 300/1000] [D loss: 0.637290] [G loss: 0.690116]\n",
      "[Frequencies: (tensor([0.0639, 0.3764, 0.0190, 0.3573, 0.0883, 0.0951]), tensor([0.0460, 0.3187, 0.0233, 0.4806, 0.0628, 0.0686])) ]\n",
      "[Scores: tensor(0.1762) tensor(0.0836) ]\n",
      "[Epoch 350/1000] [D loss: 0.688380] [G loss: 0.786824]\n",
      "[Frequencies: (tensor([0.2733, 0.0906, 0.2611, 0.0777, 0.2180, 0.0794]), tensor([0.1449, 0.2387, 0.2847, 0.0956, 0.1700, 0.0662])) ]\n",
      "[Scores: tensor(0.1213) tensor(0.0813) ]\n",
      "[Epoch 400/1000] [D loss: 0.646617] [G loss: 0.903142]\n",
      "[Frequencies: (tensor([0.2013, 0.0725, 0.0523, 0.1691, 0.1087, 0.3961]), tensor([0.0538, 0.1563, 0.0531, 0.1693, 0.1124, 0.4551])) ]\n",
      "[Scores: tensor(0.0985) tensor(0.1306) ]\n",
      "[Epoch 450/1000] [D loss: 0.649333] [G loss: 0.757737]\n",
      "[Frequencies: (tensor([0.0684, 0.2223, 0.1058, 0.3436, 0.0694, 0.1905]), tensor([0.0323, 0.2254, 0.3544, 0.2696, 0.0610, 0.0573])) ]\n",
      "[Scores: tensor(0.1293) tensor(0.0675) ]\n",
      "[Epoch 500/1000] [D loss: 0.637415] [G loss: 0.801201]\n",
      "[Frequencies: (tensor([0.6541, 0.0500, 0.1086, 0.0702, 0.0612, 0.0560]), tensor([0.0795, 0.3779, 0.2222, 0.1893, 0.0995, 0.0316])) ]\n",
      "[Scores: tensor(0.0998) tensor(0.0307) ]\n",
      "[Epoch 550/1000] [D loss: 0.681274] [G loss: 0.775484]\n",
      "[Frequencies: (tensor([0.3646, 0.0581, 0.0667, 0.1015, 0.1374, 0.2717]), tensor([0.0306, 0.1985, 0.0956, 0.3844, 0.1580, 0.1329])) ]\n",
      "[Scores: tensor(0.0404) tensor(0.0851) ]\n",
      "[Epoch 600/1000] [D loss: 0.447434] [G loss: 0.809039]\n",
      "[Frequencies: (tensor([0.3658, 0.2263, 0.0026, 0.0842, 0.0763, 0.2447]), tensor([0.0093, 0.6175, 0.0017, 0.2799, 0.0144, 0.0771])) ]\n",
      "[Scores: tensor(0.0382) tensor(0.1103) ]\n",
      "[Epoch 650/1000] [D loss: 0.433160] [G loss: 1.650958]\n",
      "[Frequencies: (tensor([0.5197, 0.0090, 0.0511, 0.0318, 0.3165, 0.0719]), tensor([0.4200, 0.0202, 0.0701, 0.0473, 0.3431, 0.0994])) ]\n",
      "[Scores: tensor(0.1244) tensor(0.2062) ]\n",
      "[Epoch 700/1000] [D loss: 0.606161] [G loss: 0.827117]\n",
      "[Frequencies: (tensor([0.0341, 0.1851, 0.0999, 0.4901, 0.0654, 0.1254]), tensor([0.0195, 0.2146, 0.1463, 0.3810, 0.0671, 0.1715])) ]\n",
      "[Scores: tensor(0.1662) tensor(0.0844) ]\n",
      "[Epoch 750/1000] [D loss: 0.632367] [G loss: 0.808777]\n",
      "[Frequencies: (tensor([0.0303, 0.3028, 0.1684, 0.2731, 0.1415, 0.0839]), tensor([0.0278, 0.2734, 0.2162, 0.2190, 0.1493, 0.1143])) ]\n",
      "[Scores: tensor(0.1798) tensor(0.0431) ]\n",
      "[Epoch 800/1000] [D loss: 0.645473] [G loss: 0.957167]\n",
      "[Frequencies: (tensor([0.2924, 0.1555, 0.0889, 0.1134, 0.2889, 0.0609]), tensor([0.0753, 0.2072, 0.1681, 0.1414, 0.3078, 0.1002])) ]\n",
      "[Scores: tensor(0.1012) tensor(0.0819) ]\n",
      "[Epoch 850/1000] [D loss: 0.683699] [G loss: 0.804278]\n",
      "[Frequencies: (tensor([0.4391, 0.1973, 0.0801, 0.1400, 0.0945, 0.0490]), tensor([0.0474, 0.3352, 0.1534, 0.2152, 0.1583, 0.0903])) ]\n",
      "[Scores: tensor(0.0634) tensor(0.0229) ]\n",
      "[Epoch 900/1000] [D loss: 0.678202] [G loss: 0.791072]\n",
      "[Frequencies: (tensor([0.4847, 0.1889, 0.0569, 0.1541, 0.0552, 0.0603]), tensor([0.0510, 0.3196, 0.1351, 0.2699, 0.1063, 0.1181])) ]\n",
      "[Scores: tensor(0.0625) tensor(0.0331) ]\n",
      "[Epoch 950/1000] [D loss: 0.655152] [G loss: 0.804381]\n",
      "[Frequencies: (tensor([0.5272, 0.1968, 0.0361, 0.1526, 0.0447, 0.0426]), tensor([0.0527, 0.3685, 0.1023, 0.2805, 0.0969, 0.0992])) ]\n",
      "[Scores: tensor(0.0742) tensor(0.0318) ]\n",
      "score after training: tensor(0.0827) tensor(0.0333)\n",
      "benchmark: tensor([0.4118, 0.1176, 0.0588, 0.1176, 0.0588, 0.2353]) tensor([0.0588, 0.3529, 0.1765, 0.2353, 0.1176, 0.0588])\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "\n",
    "# Generator params\n",
    "mem_slots = 1\n",
    "head_size = 4\n",
    "embed_size = 3\n",
    "temperature = 10\n",
    "num_heads = 6\n",
    "num_blocks = 4\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads, num_blocks)\n",
    "\n",
    "# Discriminator params\n",
    "n_embeddings = 3\n",
    "embed_size = embed_size\n",
    "out_channels = 10\n",
    "filter_sizes = [2, 3, 4] # values can be at most the sequence_length\n",
    "\n",
    "D = RelGANDiscriminator(n_embeddings, vocab_size, embed_size, sequence_length, out_channels, filter_sizes)\n",
    "\n",
    "#scores = eval_generator(G, data, vocab_size)\n",
    "scores1, scores2 = test_special_case(G, data, vocab_size, False)\n",
    "print('scores before training:', scores1, scores2)\n",
    "scores1, scores2 = test_special_case(G, data, vocab_size)\n",
    "print('distributions before training:', scores1, scores2)\n",
    "print('benchmark distributions:', alternative_weights, var_weights)\n",
    "\n",
    "# Train the GAN\n",
    "train(G, D, data, vocab_size, 1000, 0.001, temperature, 50)\n",
    "\n",
    "#scores = eval_generator(G, data, vocab_size)\n",
    "scores1, scores2 = test_special_case(G, data, vocab_size, False)\n",
    "print('scores after training:', scores1, scores2)\n",
    "scores1, scores2 = test_special_case(G, data, vocab_size)\n",
    "print('distributions after training:', scores1, scores2)\n",
    "print('benchmark distributions:', alternative_weights, var_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores after training: tensor(0.0769) tensor(0.0319)\n",
      "distributions after training: tensor([0.5007, 0.2659, 0.0405, 0.1244, 0.0410, 0.0275]) tensor([0.0644, 0.4216, 0.1114, 0.2473, 0.0923, 0.0630])\n",
      "benchmark distributions: tensor([0.4118, 0.1176, 0.0588, 0.1176, 0.0588, 0.2353]) tensor([0.0588, 0.3529, 0.1765, 0.2353, 0.1176, 0.0588])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores1, scores2 = test_special_case(G, data, vocab_size, False)\n",
    "print('scores after training:', scores1, scores2)\n",
    "scores1, scores2 = test_special_case(G, data, vocab_size)\n",
    "print('distributions after training:', scores1, scores2)\n",
    "print('benchmark distributions:', alternative_weights, var_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
