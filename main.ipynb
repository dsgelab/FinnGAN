{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15962041257352351903\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16591054485076167791\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4424036384668240335\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11276946637\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15242822112926518825\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import time\n",
    "from math import log10, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "n_vars = 3\n",
    "var_ids = list(range(n_vars))\n",
    "var_names = ['var' + str(i) for i in var_ids]\n",
    "var_weights = [0.1, 0.6, 0.3] # variable distribution of mock data\n",
    "n_time_steps = 6\n",
    "n_individuals = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function(s)\n",
    "\n",
    "# round a number to n significant digits\n",
    "def round_to_n(x, n = 2):\n",
    "    return round(x, -int(floor(log10(abs(x)))) + (n - 1)) if x != 0 else 0\n",
    "\n",
    "# visualize the output of the generator\n",
    "def visualize_output(generator, z, n = 2):\n",
    "    p = np.reshape(generator.predict(z), (n_time_steps, n_vars))\n",
    "    p.shape\n",
    "    for t in range(p.shape[0]):\n",
    "        tmp = []\n",
    "        for f in range(p.shape[1]):\n",
    "            tmp.append(round_to_n(p[t,f], n))\n",
    "        print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.13 seconds\n",
      "['var1', 'var0', 'var1', 'var1', 'var2', 'var1']\n",
      "['var1', 'var1', 'var2']\n",
      "['var1', 'var0', 'var1']\n",
      "['var0', 'var2', 'var2', 'var2', 'var1']\n",
      "['var1', 'var2', 'var1', 'var2', 'var1', 'var1']\n",
      "['var1', 'var1', 'var1', 'var1', 'var1']\n",
      "['var1', 'var1', 'var0', 'var2', 'var1']\n",
      "['var2', 'var1', 'var1', 'var1', 'var1', 'var1']\n",
      "['var1', 'var1', 'var2', 'var1', 'var1']\n",
      "['var1', 'var0', 'var2', 'var0']\n"
     ]
    }
   ],
   "source": [
    "# Generate mock data\n",
    "\n",
    "events = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for indv in range(n_individuals):\n",
    "    tmp = []\n",
    "    for t in range(np.random.randint(n_time_steps // 2, n_time_steps + 1)):\n",
    "        var = np.random.choice(var_names, p=var_weights)\n",
    "        tmp.append(var)\n",
    "    events.append(tmp)\n",
    "        \n",
    "print('time taken:', round_to_n(time.time() - start_time), 'seconds')\n",
    "\n",
    "for i in range(10):\n",
    "    print(events[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 1, 1, 2, 1],\n",
       "       [1, 1, 2, 0, 0, 0],\n",
       "       [1, 3, 1, 0, 0, 0],\n",
       "       [3, 2, 2, 2, 1, 0],\n",
       "       [1, 2, 1, 2, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 0],\n",
       "       [1, 1, 3, 2, 1, 0],\n",
       "       [2, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 2, 1, 1, 0],\n",
       "       [1, 3, 2, 3, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the data into a format required by the Embedding layer\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(events)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "encoded_data = t.texts_to_sequences(events)\n",
    "data = pad_sequences(encoded_data, maxlen=n_time_steps, padding='post')\n",
    "data[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6) (200, 6)\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into train and test sets \n",
    "\n",
    "data_train, data_test = train_test_split(data, test_size = 0.2)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 6, 3)              12        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 180       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 198\n",
      "Trainable params: 198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the discriminator\n",
    "\n",
    "discriminator = Sequential(name = 'discriminator')\n",
    "discriminator.add(Embedding(vocab_size, 3, input_length=n_time_steps))\n",
    "discriminator.add(LSTM(5))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "#discriminator = Model(inp_d, out_d, name='discriminator')\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50223106]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data_train[0]\n",
    "discriminator.predict(np.reshape(x, (1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6, 3)]            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 6, 5)              180       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6, 3)              18        \n",
      "=================================================================\n",
      "Total params: 198\n",
      "Trainable params: 198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the generator\n",
    "# TODO: implement RelGAN to some extent\n",
    "\n",
    "noise_length = 3\n",
    "\n",
    "inp_g = Input(shape=(n_time_steps, noise_length))\n",
    "lstm_g = LSTM(5, return_sequences=True)(inp_g)\n",
    "out_g = Dense(3, activation='softmax')(lstm_g)\n",
    "generator = Model(inp_g, out_g, name='generator')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.random.normal(scale = 0.5, size = (1, n_time_steps, noise_length))\n",
    "generator.predict(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator (Model)        (None, 1)                 186       \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the trainable discriminator model\n",
    "discriminator.trainable = True\n",
    "\n",
    "discriminator_model = Sequential()\n",
    "discriminator_model.add(discriminator)\n",
    "discriminator_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator (Model)            (None, 20, 3)             673       \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 186       \n",
      "=================================================================\n",
      "Total params: 859\n",
      "Trainable params: 673\n",
      "Non-trainable params: 186\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the trainable adversarial model\n",
    "discriminator.trainable = False\n",
    "\n",
    "adversarial_model = Sequential()\n",
    "adversarial_model.add(generator)\n",
    "adversarial_model.add(discriminator)\n",
    "adversarial_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "adversarial_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train function\n",
    "\n",
    "def train(batch_size = 50, epochs = 10, print_step = 1):\n",
    "    for epoch in range(epochs):\n",
    "        idx_true = np.random.choice(data_train.shape[0], size = batch_size, replace = False)\n",
    "        x_true = data_train[idx_true, :, :]\n",
    "        z = np.random.normal(scale = 1, size = (batch_size, n_time_steps, noise_length))\n",
    "        \n",
    "        x_fake = generator.predict(z)\n",
    "        \n",
    "        x = np.concatenate((x_true, x_fake))\n",
    "        y = np.ones([2 * batch_size, 1])\n",
    "        y[batch_size:, :] = 0\n",
    "        discriminator.trainable = True\n",
    "        d_loss = discriminator_model.train_on_batch(x, y)\n",
    "        \n",
    "        y = np.ones([batch_size, 1])\n",
    "        discriminator.trainable = False\n",
    "        z = np.random.normal(scale = 1, size = (batch_size, n_time_steps, noise_length)) \n",
    "        a_loss = adversarial_model.train_on_batch(z, y)\n",
    "        \n",
    "        if (epoch % print_step) == 0:\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (epoch, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [D loss: 0.715298, acc: 0.500000]  [A loss: 0.816451, acc: 0.000000]\n",
      "50: [D loss: 0.663767, acc: 0.520000]  [A loss: 0.812898, acc: 0.000000]\n",
      "100: [D loss: 0.727041, acc: 0.325000]  [A loss: 0.614322, acc: 1.000000]\n",
      "150: [D loss: 0.623657, acc: 0.890000]  [A loss: 0.790276, acc: 0.000000]\n",
      "200: [D loss: 0.842737, acc: 0.265000]  [A loss: 0.549213, acc: 0.780000]\n",
      "250: [D loss: 0.737081, acc: 0.500000]  [A loss: 0.819864, acc: 0.000000]\n",
      "300: [D loss: 0.505884, acc: 0.980000]  [A loss: 1.137674, acc: 0.000000]\n",
      "350: [D loss: 0.501969, acc: 0.825000]  [A loss: 1.086113, acc: 0.260000]\n",
      "400: [D loss: 0.662116, acc: 0.490000]  [A loss: 0.555154, acc: 1.000000]\n",
      "450: [D loss: 0.540381, acc: 0.985000]  [A loss: 0.792217, acc: 0.010000]\n",
      "time taken: 150.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# run training function\n",
    "\n",
    "start_time = time.time()\n",
    "train(batch_size = 100, epochs = 500, print_step = 50)\n",
    "print('time taken:', round_to_n(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.5, 0.3]\n",
      "[0.2, 0.6, 0.2]\n",
      "[0.2, 0.5, 0.3]\n",
      "[0.2, 0.6, 0.3]\n",
      "[0.1, 0.6, 0.3]\n",
      "[0.1, 0.7, 0.2]\n",
      "[0.08, 0.7, 0.2]\n",
      "[0.07, 0.6, 0.3]\n",
      "[0.07, 0.5, 0.5]\n",
      "[0.05, 0.6, 0.3]\n",
      "[0.03, 0.7, 0.2]\n",
      "[0.03, 0.7, 0.3]\n",
      "[0.03, 0.7, 0.3]\n",
      "[0.02, 0.7, 0.3]\n",
      "[0.03, 0.6, 0.4]\n",
      "[0.02, 0.6, 0.3]\n",
      "[0.02, 0.7, 0.3]\n",
      "[0.03, 0.5, 0.5]\n",
      "[0.03, 0.4, 0.5]\n",
      "[0.03, 0.4, 0.5]\n"
     ]
    }
   ],
   "source": [
    "z = np.random.normal(scale = 0.5, size = (1, n_time_steps, noise_length))\n",
    "visualize_output(generator, z, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
