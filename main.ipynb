{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from math import log10, floor\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from math import ceil, isnan\n",
    "import sys\n",
    "try:\n",
    "    import torchtext\n",
    "    from torchtext.data import Field, Iterator, Dataset, Example\n",
    "except ImportError: \n",
    "    !{'/opt/anaconda3/bin/python3'} -m pip install --upgrade git+https://github.com/pytorch/text\n",
    "    import torchtext\n",
    "    from torchtext.data import Field, Iterator, Dataset\n",
    "\n",
    "from relational_rnn_models import RelationalMemoryGenerator\n",
    "from discriminator import RelGANDiscriminator\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# Try setting the device to a GPU\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function(s)\n",
    "\n",
    "# round a number to n significant digits\n",
    "def round_to_n(x, n = 2):\n",
    "    return round(x, -int(floor(log10(abs(x)))) + (n - 1)) if x != 0 else 0\n",
    "\n",
    "# Transform a date string into a datetime object\n",
    "def str_to_datetime(string):\n",
    "    return datetime.datetime.strptime(string, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# TODO: more complex reduction: takes into account different ICD groups?\n",
    "def reduce_icd(icd_full):\n",
    "    return icd_full[:2]\n",
    "\n",
    "def get_distribution(data, field, vocab_size, fake = True):\n",
    "    counts = torch.zeros(vocab_size)\n",
    "\n",
    "    for i in range(vocab_size):\n",
    "        if fake:\n",
    "            counts[i] = torch.sum(data == i)\n",
    "        else:\n",
    "            counts[i] = field.vocab.freqs[field.vocab.itos[i]]\n",
    "\n",
    "    freqs = counts / torch.sum(counts)\n",
    "    \n",
    "    return counts, freqs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FINNGENID', 'EVENT_AGE', 'EVENT_YEAR', 'ENDPOINT'], dtype='object')\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/FINNGEN_ENDPOINTS_DF3_longitudinal_V1_for_SandBox.txt.gz'\n",
    "\n",
    "events = pd.read_csv(filename, compression = 'infer', nrows = 200000, sep='\\t')\n",
    "\n",
    "print(events.columns)\n",
    "\n",
    "subjects = events['FINNGENID'].unique()\n",
    "n_individuals = len(subjects)\n",
    "print(n_individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    211.000000\n",
      "mean      32.038957\n",
      "std       10.313633\n",
      "min        2.950000\n",
      "25%       22.715000\n",
      "50%       33.960000\n",
      "75%       41.000000\n",
      "max       51.530000\n",
      "dtype: float64\n",
      "count      211.000000\n",
      "mean       947.867299\n",
      "std       1490.806688\n",
      "min         12.000000\n",
      "25%        170.000000\n",
      "50%        395.000000\n",
      "75%       1198.000000\n",
      "max      15208.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(events.groupby('FINNGENID').apply(lambda x: x['EVENT_AGE'].max() - x['EVENT_AGE'].min()).describe())\n",
    "print(events.groupby('FINNGENID').apply(lambda x: len(x)).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 15\n",
    "\n",
    "sequence_length = min(events.groupby('FINNGENID').apply(lambda x: len(x)).max(), max_sequence_length)\n",
    "print(sequence_length)\n",
    "\n",
    "def get_sequence_of_codes(subject):\n",
    "    codes = []\n",
    "    \n",
    "    count = 0\n",
    "    for i in subject.sort_values('EVENT_AGE').index:\n",
    "        codes.append(subject.loc[i, 'ENDPOINT'])\n",
    "        count += 1\n",
    "        if count == sequence_length:\n",
    "            break\n",
    "        \n",
    "    res = ' '.join(codes)\n",
    "    return res\n",
    "\n",
    "def get_sequence_of_time_differences(subject):\n",
    "    times = [0]\n",
    "    \n",
    "    count = 0\n",
    "    for i in subject.sort_values('EVENT_AGE').index:\n",
    "        times.append(subject.loc[i, 'EVENT_AGE'])\n",
    "        count += 1\n",
    "        if count == sequence_length:\n",
    "            break\n",
    "        \n",
    "    res = np.diff(times)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    211.000000\n",
      "mean      14.976303\n",
      "std        0.247670\n",
      "min       12.000000\n",
      "25%       15.000000\n",
      "50%       15.000000\n",
      "75%       15.000000\n",
      "max       15.000000\n",
      "dtype: float64\n",
      "(211,)\n",
      "count    211.000000\n",
      "mean      14.976303\n",
      "std        0.247670\n",
      "min       12.000000\n",
      "25%       15.000000\n",
      "50%       15.000000\n",
      "75%       15.000000\n",
      "max       15.000000\n",
      "dtype: float64\n",
      "(211,)\n"
     ]
    }
   ],
   "source": [
    "sequences_of_codes = events.groupby('FINNGENID').apply(get_sequence_of_codes)\n",
    "#print(sequences_of_codes.head())\n",
    "print(sequences_of_codes.apply(lambda x: len(x.split(' '))).describe())\n",
    "print(sequences_of_codes.shape)\n",
    "\n",
    "sequences_of_times = events.groupby('FINNGENID').apply(get_sequence_of_time_differences)\n",
    "#print(sequences_of_times.head())\n",
    "print(sequences_of_times.apply(lambda x: len(x)).describe())\n",
    "print(sequences_of_times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 2)\n"
     ]
    }
   ],
   "source": [
    "#sequences = pd.DataFrame({'ENDPOINTS': sequences_of_codes.stack(), 'TIME_DIFFS': sequences_of_times.stack()})\n",
    "sequences = pd.DataFrame({'ENDPOINTS': sequences_of_codes, 'TIME_DIFFS': sequences_of_times})\n",
    "print(sequences.shape)\n",
    "#sequences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52602071/dataframe-as-datasource-in-torchtext\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "            examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): use only exanples for which\n",
    "                filter_pred(example) is true, or use all examples if None.\n",
    "                Default is None\n",
    "        \"\"\"\n",
    "        self.fields = dict(fields)\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(self.fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "\n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "        for key, field in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 2) (22, 2)\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda x: x.split(' ')\n",
    "\n",
    "ENDPOINT = Field(fix_length = sequence_length, tokenize = tokenize)\n",
    "\n",
    "fields = [('ENDPOINTS', ENDPOINT), ('TIME_DIFFS', None)]\n",
    "\n",
    "train_sequences, val_sequences = train_test_split(sequences, test_size = 0.1)\n",
    "print(train_sequences.shape, val_sequences.shape)\n",
    "\n",
    "train = DataFrameDataset(train_sequences, fields)\n",
    "val = DataFrameDataset(val_sequences, fields)\n",
    "\n",
    "ENDPOINT.build_vocab(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "ANY_ATC\n",
      "377\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "print(ENDPOINT.vocab.stoi['ANY_ATC'])\n",
    "print(ENDPOINT.vocab.itos[2])\n",
    "vocab_size = len(ENDPOINT.vocab.freqs) + 2\n",
    "print(vocab_size)\n",
    "\n",
    "print(ENDPOINT.vocab.freqs[ENDPOINT.vocab.itos[3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 15])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_iter = Iterator(val, batch_size = len(val_sequences), repeat = True)\n",
    "\n",
    "next(iter(val_iter)).ENDPOINTS.transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "0.11911532385466035\n"
     ]
    }
   ],
   "source": [
    "subjects = sequences.index\n",
    "n_individuals = len(subjects)\n",
    "print(n_individuals)\n",
    "print(vocab_size / (n_individuals * sequence_length)) # The lower this is the easier it is for the generator to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], device='cuda:0')\n",
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[  0,  21, 270, 155, 376, 299, 156, 259, 237,  61, 159,  11,  62, 340,\n",
      "         234]], device='cuda:0')\n",
      "tensor([[[ 1.6821,  1.4918, -1.4065, -1.0839],\n",
      "         [ 1.6526,  1.8030, -1.3940, -1.0935],\n",
      "         [ 1.5192,  1.5406, -1.0861, -1.1276],\n",
      "         [ 1.5181,  1.6995, -1.2751, -1.0744]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test generator output\n",
    "\n",
    "mem_slots = 4\n",
    "head_size = 2\n",
    "embed_size = 2\n",
    "temperature = 1\n",
    "num_heads = 2\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads)\n",
    "\n",
    "start_token = torch.tensor([[0]])\n",
    "memory = G.initial_state(batch_size = 1)\n",
    "\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    start_token = start_token.cuda()\n",
    "    memory = memory.cuda()\n",
    "\n",
    "print(memory)\n",
    "logits, tokens, _, memory = G(start_token, memory, sequence_length, None)\n",
    "print(logits)\n",
    "print(tokens)\n",
    "print(memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2090)\n"
     ]
    }
   ],
   "source": [
    "# Define generator evaluation functions\n",
    "\n",
    "def chi_sqrd_dist(counts1, counts2, eps = 1e-20):\n",
    "    counts1 = counts1.view(1, -1)\n",
    "    counts2 = counts2.view(1, -1)\n",
    "    table = torch.cat([counts1, counts2], dim = 0)\n",
    "    col_sums = torch.sum(table, dim = 0)\n",
    "    row_sums = torch.sum(table, dim = 1)\n",
    "    n = torch.sum(col_sums)\n",
    "    \n",
    "    table_freq = table / n\n",
    "    col_freqs = col_sums / n\n",
    "    row_freqs = row_sums / n\n",
    "    \n",
    "    diffs = table_freq[0, :] / (row_freqs[0] + eps) - table_freq[1, :] / (row_freqs[1] + eps)\n",
    "    diffs_sqrd = diffs ** 2\n",
    "    diffs_sqrd_norm = diffs_sqrd / (col_freqs + eps)\n",
    "    \n",
    "    chi_sqrd_distance = torch.sum(diffs_sqrd_norm)\n",
    "    \n",
    "    return chi_sqrd_distance\n",
    "\n",
    "def get_fake_distribution(G, start_tokens, vocab_size = vocab_size, sequence_length = sequence_length):\n",
    "    memory = G.initial_state(batch_size = start_tokens.shape[0])\n",
    "\n",
    "    if cuda:\n",
    "        memory = memory.cuda()\n",
    "        start_tokens = start_tokens.cuda()\n",
    "    \n",
    "    _, data_fake, _, _ = G(start_tokens, memory, sequence_length)\n",
    "    \n",
    "    counts_fake, freqs_fake = get_distribution(data_fake, None, vocab_size, fake = True)\n",
    "    \n",
    "    return counts_fake, freqs_fake\n",
    "    \n",
    "def get_score(G, ENDPOINT, start_tokens, vocab_size = vocab_size, sequence_length = sequence_length):\n",
    "    counts_real, freqs_real = get_distribution(None, ENDPOINT, vocab_size, fake = False)\n",
    "    \n",
    "    counts_fake, freqs_fake = get_fake_distribution(G, start_tokens, vocab_size, sequence_length)\n",
    "    \n",
    "    score = chi_sqrd_dist(counts_real, counts_fake)\n",
    "    return score\n",
    "\n",
    "val_data = next(iter(val_iter)).ENDPOINTS.transpose(0, 1)\n",
    "\n",
    "score = get_score(G, ENDPOINT, val_data[:, :1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.5811, 0.5811]], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.5811], device='cuda:0', grad_fn=<MeanBackward2>)\n"
     ]
    }
   ],
   "source": [
    "# Test Discriminator output\n",
    "\n",
    "n_embeddings = 2\n",
    "embed_size = 2\n",
    "out_channels = 5 \n",
    "filter_sizes = [2, 3] # values can be at most the sequence_length\n",
    "\n",
    "D = RelGANDiscriminator(n_embeddings, vocab_size, embed_size, sequence_length, out_channels, filter_sizes)\n",
    "\n",
    "if cuda:\n",
    "    D.cuda()\n",
    "\n",
    "inp = logits\n",
    "print(inp)\n",
    "print(D(inp, False))\n",
    "print(D(inp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator pre-train function\n",
    "\n",
    "def pretrain_generator(G, train, batch_size, vocab_size, sequence_length, n_epochs, lr, print_step = 10):\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    \n",
    "    if cuda:\n",
    "        G.cuda()\n",
    "        loss_function.cuda()\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        train_iter = Iterator(train, batch_size = batch_size, device = device)\n",
    "        loss_total = 0\n",
    "        count = 0\n",
    "        \n",
    "        for batch in train_iter:\n",
    "            train_data = batch.ENDPOINTS.transpose(0, 1)\n",
    "            train_data_one_hot = F.one_hot(train_data, vocab_size).type(Tensor)\n",
    "            \n",
    "            start_token = train_data[:, :1]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            memory = G.initial_state(batch_size = train_data.shape[0])\n",
    "\n",
    "            if cuda:\n",
    "                start_token = start_token.cuda()\n",
    "                memory = memory.cuda()\n",
    "\n",
    "            logits, _, _, _ = G(start_token, memory, sequence_length)\n",
    "\n",
    "            loss = loss_function(logits, train_data_one_hot)\n",
    "            \n",
    "            loss_total += loss.item()\n",
    "            count += 1\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "        if e % print_step == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [G loss: %f]\"\n",
    "                % (e, n_epochs, loss_total / count)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0981)\n",
      "[Epoch 0/10] [G loss: 0.136497]\n",
      "[Epoch 1/10] [G loss: 0.136503]\n",
      "[Epoch 2/10] [G loss: 0.136234]\n",
      "[Epoch 3/10] [G loss: 0.136137]\n",
      "[Epoch 4/10] [G loss: 0.135988]\n",
      "[Epoch 5/10] [G loss: 0.135937]\n",
      "[Epoch 6/10] [G loss: 0.134428]\n",
      "[Epoch 7/10] [G loss: 0.134943]\n",
      "[Epoch 8/10] [G loss: 0.135320]\n",
      "[Epoch 9/10] [G loss: 0.133754]\n",
      "tensor(3.2361)\n"
     ]
    }
   ],
   "source": [
    "mem_slots = 4\n",
    "head_size = 2\n",
    "embed_size = 2\n",
    "temperature = 1\n",
    "num_heads = 2\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads)\n",
    "\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    \n",
    "val_data = next(iter(val_iter)).ENDPOINTS.transpose(0, 1)\n",
    "\n",
    "score = get_score(G, ENDPOINT, val_data[:, :1])\n",
    "print(score)\n",
    "\n",
    "batch_size = 10\n",
    "pretrain_generator(G, train, batch_size, vocab_size, sequence_length, 10, 0.01, print_step = 1)\n",
    "\n",
    "score = get_score(G, ENDPOINT, val_data[:, :1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "\n",
    "def train_GAN(G, D, train, val_iter, batch_size, vocab_size, sequence_length, n_epochs, lr, temperature, print_step = 10, score_fn = get_score):    \n",
    "    scores = []\n",
    "    \n",
    "    val_data = next(iter(val_iter)).ENDPOINTS.transpose(0, 1)\n",
    "    \n",
    "    score = score_fn(G, ENDPOINT, val_data[:, :1])\n",
    "    print('Score before training:', score)\n",
    "    scores.append(torch.tensor(score))\n",
    "    \n",
    "    print('pretraining generator...')\n",
    "    pretrain_generator(G, train, batch_size, vocab_size, sequence_length, max(n_epochs // 10, 1), lr * 100, print_step = max(n_epochs // 10 - 1, 1))\n",
    "    print('pretraining complete')\n",
    "    \n",
    "    score = score_fn(G, ENDPOINT, val_data[:, :1])\n",
    "    print(\"[Score:\", score, \"]\")\n",
    "    scores.append(torch.tensor(score))\n",
    "    \n",
    "    adversarial_loss = torch.nn.BCELoss()\n",
    "    \n",
    "    optimizer_G = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    optimizer_D = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "    \n",
    "    if cuda:\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        adversarial_loss.cuda()\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        train_iter = Iterator(train, batch_size = batch_size, device = device)\n",
    "        #loss_total = 0\n",
    "        #count = 0\n",
    "        \n",
    "        for batch in train_iter:\n",
    "            train_data = batch.ENDPOINTS.transpose(0, 1)\n",
    "            train_data_one_hot = F.one_hot(train_data, vocab_size).type(Tensor)\n",
    "\n",
    "            start_token = train_data[:, :1]\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            valid = Variable(Tensor(train_data.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(train_data.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Generate a batch of images\n",
    "            memory = G.initial_state(batch_size = train_data.shape[0])\n",
    "            if cuda:\n",
    "                memory = memory.cuda()\n",
    "\n",
    "            temp = temperature ** ((e + 1) / n_epochs)\n",
    "            fake_one_hot, _, _, _ = G(start_token, memory, sequence_length, temp)\n",
    "\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            g_loss = adversarial_loss(D(fake_one_hot), valid)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            real_loss = adversarial_loss(D(train_data_one_hot), valid)\n",
    "            fake_loss = adversarial_loss(D(fake_one_hot.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        if e % print_step == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (e, n_epochs, d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            score = score_fn(G, ENDPOINT, val_data[:, :1])\n",
    "            print(\"[Score:\", score, \"]\")\n",
    "            scores.append(torch.tensor(score))\n",
    "            \n",
    "    score = score_fn(G, ENDPOINT, val_data[:, :1])\n",
    "    print('Score after training:', score)\n",
    "    scores.append(torch.tensor(score))\n",
    "            \n",
    "    # return scores\n",
    "    return torch.stack(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score before training: tensor(4.2018)\n",
      "pretraining generator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [G loss: 0.136554]\n",
      "[Epoch 9/10] [G loss: 0.136547]\n",
      "pretraining complete\n",
      "[Score: tensor(9.6698) ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([61, 1])) that is different to the input size (torch.Size([61])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [D loss: 0.699371] [G loss: 0.569278]\n",
      "[Score: tensor(9.5396) ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/100] [D loss: 0.692837] [G loss: 0.576079]\n",
      "[Score: tensor(9.5940) ]\n",
      "[Epoch 20/100] [D loss: 0.688239] [G loss: 0.583649]\n",
      "[Score: tensor(9.5352) ]\n",
      "[Epoch 30/100] [D loss: 0.679471] [G loss: 0.604871]\n",
      "[Score: tensor(9.3361) ]\n",
      "[Epoch 40/100] [D loss: 0.671569] [G loss: 0.636145]\n",
      "[Score: tensor(9.3375) ]\n",
      "[Epoch 50/100] [D loss: 0.663424] [G loss: 0.628789]\n",
      "[Score: tensor(9.1522) ]\n",
      "[Epoch 60/100] [D loss: 0.646152] [G loss: 0.644570]\n",
      "[Score: tensor(8.8536) ]\n",
      "[Epoch 70/100] [D loss: 0.624781] [G loss: 0.736600]\n",
      "[Score: tensor(7.7848) ]\n",
      "[Epoch 80/100] [D loss: 0.622917] [G loss: 0.825052]\n",
      "[Score: tensor(7.2452) ]\n",
      "[Epoch 90/100] [D loss: 0.596574] [G loss: 0.866850]\n",
      "[Score: tensor(7.2747) ]\n",
      "Score after training: tensor(7.4065)\n",
      "time taken: 100.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generator params\n",
    "mem_slots = 1\n",
    "head_size = 6\n",
    "embed_size = 10\n",
    "temperature = 100\n",
    "num_heads = 10\n",
    "num_blocks = 6\n",
    "\n",
    "G = RelationalMemoryGenerator(mem_slots, head_size, embed_size, vocab_size, temperature, num_heads, num_blocks)\n",
    "\n",
    "# Discriminator params\n",
    "n_embeddings = 5\n",
    "embed_size = embed_size\n",
    "out_channels = 15\n",
    "filter_sizes = [2, 3, 4] # values can be at most the sequence_length\n",
    "\n",
    "D = RelGANDiscriminator(n_embeddings, vocab_size, embed_size, sequence_length, out_channels, filter_sizes)\n",
    "\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "\n",
    "val_data = next(iter(val_iter)).ENDPOINTS.transpose(0, 1)\n",
    "    \n",
    "#_, freqs = get_distribution(None, ENDPOINT, vocab_size, fake = False)\n",
    "#_, freqs_fake = get_fake_distribution(G, val_data[:, :1])\n",
    "#print('distribution before training:', freqs_fake)\n",
    "#print('benchmark distribution:', freqs)\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 100\n",
    "print_step = n_epochs // 10\n",
    "lr = 1e-4\n",
    "\n",
    "# Train the GAN\n",
    "scores = train_GAN(G, D, train, val_iter, batch_size, vocab_size, sequence_length, n_epochs, lr, temperature, print_step = print_step)\n",
    "\n",
    "#_, freqs_fake = get_fake_distribution(G, val_data[:, :1])\n",
    "#print('distributions after training:', freqs_fake)\n",
    "#print('benchmark distribution:', freqs)\n",
    "\n",
    "print('time taken:', round_to_n(time.time() - start_time), 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.2018, 9.6698, 9.5396, 9.5940, 9.5352, 9.3361, 9.3375, 9.1522, 8.8536,\n",
      "        7.7848, 7.2452, 7.2747, 7.4065])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(scores.shape[0]), scores.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
